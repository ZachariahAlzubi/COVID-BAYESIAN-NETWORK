{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FIPS state  Week  current_week_cases  next_week_cases\n",
      "0  1001    AL     1                  10             20.0\n",
      "1  1001    AL     2                  20             30.0\n",
      "2  1001    AL     3                  30              NaN\n",
      "3  1003    AL     1                  40             50.0\n",
      "4  1003    AL     2                  50             60.0\n",
      "5  1003    AL     3                  60              NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    \"FIPS\": [1001, 1001, 1001, 1003, 1003, 1003],\n",
    "    \"state\": [\"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\"],\n",
    "    \"Week\": [1, 2, 3, 1, 2, 3],\n",
    "    \"cases\": [10, 20, 30, 40, 50, 60]\n",
    "})\n",
    "\n",
    "# Step 1: Sort the DataFrame\n",
    "data = data.sort_values(by=[\"FIPS\", \"state\", \"Week\"])\n",
    "\n",
    "# Step 2: Shift the cases column to create next_week_cases\n",
    "data['next_week_cases'] = data.groupby(['FIPS', 'state'])['cases'].shift(-1)\n",
    "\n",
    "# Step 3: Rename the original cases column and create the final DataFrame\n",
    "data.rename(columns={'cases': 'current_week_cases'}, inplace=True)\n",
    "final_df = data[['FIPS', 'state', 'Week', 'current_week_cases', 'next_week_cases']]\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable  1001_current  1001_next  1003_current  1003_next\n",
      "Week                                                      \n",
      "1                 10.0       20.0          40.0       50.0\n",
      "2                 20.0       30.0          50.0       60.0\n",
      "3                 30.0        NaN          60.0        NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your existing DataFrame from the previous transformation\n",
    "# Sample DataFrame creation (replicating previous final data structure)\n",
    "# data = pd.DataFrame({\n",
    "#     \"FIPS\": [1001, 1001, 1001, 1003, 1003, 1003],\n",
    "#     \"state\": [\"AL\", \"AL\", \"AL\", \"AL\", \"AL\", \"AL\"],\n",
    "#     \"Week\": [1, 2, 3, 1, 2, 3],\n",
    "#     \"current_week_cases\": [10, 20, 30, 40, 50, 60],\n",
    "#     \"next_week_cases\": [20, 30, None, 50, 60, None]\n",
    "# })\n",
    "data = final_df\n",
    "\n",
    "# Step 1: Create new DataFrame for pgmpy input\n",
    "# We need to make two entries per row: one for _current and one for _next\n",
    "data_current = data[['FIPS', 'Week', 'current_week_cases']].copy()\n",
    "data_next = data[['FIPS', 'Week', 'next_week_cases']].copy()\n",
    "\n",
    "# Rename columns\n",
    "data_current.columns = ['FIPS', 'Week', 'cases']\n",
    "data_next.columns = ['FIPS', 'Week', 'cases']\n",
    "\n",
    "# Add a suffix to distinguish between current and next\n",
    "data_current['variable'] = data_current['FIPS'].astype(str) + '_current'\n",
    "data_next['variable'] = data_next['FIPS'].astype(str) + '_next'\n",
    "\n",
    "# Concatenate both DataFrames vertically\n",
    "pgmpy_data = pd.concat([data_current, data_next], ignore_index=True)\n",
    "\n",
    "# Pivot to wide format\n",
    "pgmpy_data = pgmpy_data.pivot_table(index='Week', columns='variable', values='cases', aggfunc='first')\n",
    "\n",
    "# Flatten the columns MultiIndex (not needed here, just simplifying)\n",
    "pgmpy_data.columns = pgmpy_data.columns.get_level_values(0)\n",
    "\n",
    "# The resulting DataFrame\n",
    "print(pgmpy_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['1001_current', '1001_next', '1003_current', '1003_next'], dtype='object', name='variable')\n"
     ]
    }
   ],
   "source": [
    "print(pgmpy_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable 1001_current 1001_next 1003_current 1003_next\n",
      "Week                                                  \n",
      "1               bin_1     bin_2        bin_1     bin_2\n",
      "2               bin_2     bin_4        bin_2     bin_4\n",
      "3               bin_4       NaN        bin_4       NaN\n",
      "   1003_current  1003_next  1001_current  1001_next\n",
      "0          40.0       40.0          10.0       10.0\n",
      "1          48.0       48.0          18.0       18.0\n",
      "2          50.0       50.0          20.0       20.0\n",
      "3          54.0       54.0          24.0       24.0\n",
      "4          60.0       60.0          30.0       30.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dictionary to store bin edges\n",
    "bin_edges_dict = {}\n",
    "\n",
    "# Function to calculate quantile-based bins and apply discretization\n",
    "def discretize_columns(df, fip):\n",
    "    current_col = f\"{fip}_current\"\n",
    "    next_col = f\"{fip}_next\"\n",
    "    # Combine current and next week cases to get full range of data for binning\n",
    "    combined_series = pd.concat([df[current_col], df[next_col]]).dropna()\n",
    "    # Calculate the quantile edges\n",
    "    quantiles = np.linspace(0, 1, 6)\n",
    "    bin_edges = combined_series.quantile(quantiles)\n",
    "    # Ensure uniqueness and sort them\n",
    "    unique_edges = sorted(set(bin_edges))\n",
    "    # Store bin edges in dictionary\n",
    "    bin_edges_dict[current_col] = unique_edges\n",
    "    bin_edges_dict[next_col] = unique_edges\n",
    "    # Discretize both columns using the same bin edges\n",
    "    labels = [f\"bin_{i+1}\" for i in range(len(unique_edges)-1)]\n",
    "    df[current_col] = pd.cut(df[current_col], bins=unique_edges, labels=labels, include_lowest=True)\n",
    "    df[next_col] = pd.cut(df[next_col], bins=unique_edges, labels=labels, include_lowest=True)\n",
    "\n",
    "# Apply the discretization function to each FIP group\n",
    "fips = set(col.split('_')[0] for col in pgmpy_data.columns)\n",
    "for fip in fips:\n",
    "    discretize_columns(pgmpy_data, fip)\n",
    "\n",
    "# Create a DataFrame from the bin edges dictionary\n",
    "bin_edges_df = pd.DataFrame.from_dict(bin_edges_dict, orient='index').T\n",
    "\n",
    "# The resulting DataFrames\n",
    "print(pgmpy_data)\n",
    "print(bin_edges_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid-bn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
