{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d899fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d5bb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shapefile_path = \"UScounties.shp\"\n",
    "# gdf = gpd.read_file(shapefile_path)\n",
    "# print(gdf.head())\n",
    "# gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55dfdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"covidData2021-2022.csv\", dtype={'date': pd.StringDtype(), 'county': pd.StringDtype(), 'state': pd.StringDtype(), 'fips': pd.StringDtype(), 'cases': pd.Int64Dtype(), 'deaths': pd.Int64Dtype()},keep_default_na=False,na_values=pd.NA)\n",
    "covid_data=pd.read_csv(\"covidData2021-2022.csv\")\n",
    "\n",
    "\n",
    "covid_data[\"date\"] = pd.to_datetime(covid_data[\"date\"])\n",
    "print(covid_data.head(-20))\n",
    "print(covid_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b08c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming the data is already loaded and named as `df`\n",
    "covid_data['daily_new_cases'] = covid_data.groupby(['county', 'state'])['cases'].diff().fillna(covid_data['cases'])\n",
    "covid_data['daily_new_cases'] = covid_data['daily_new_cases'].apply(lambda x: x if x >= 0 else 0)\n",
    "\n",
    "# Summing up daily new cases across all counties and states for each day\n",
    "daily_new_cases = covid_data.groupby('date')['daily_new_cases'].sum().reset_index()\n",
    "\n",
    "# Plotting the daily new COVID-19 cases\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daily_new_cases['date'], daily_new_cases['daily_new_cases'], label='Daily New Cases', color='red')\n",
    "plt.title('Daily New COVID-19 Cases Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Daily New Cases')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert 'date' to datetime object\n",
    "covid_data['date'] = pd.to_datetime(covid_data['date'])\n",
    "\n",
    "# Find the end of week date (Friday) for each entry\n",
    "covid_data['end_of_week'] = covid_data['date'] + pd.to_timedelta(\n",
    "    (4 - covid_data['date'].dt.weekday) % 7, unit='d')\n",
    "\n",
    "# Now group by 'end_of_week' and 'fips' and sum the 'daily_new_cases'\n",
    "weekly_cases = covid_data.groupby(['fips','state', 'end_of_week'])['daily_new_cases'].sum().reset_index()\n",
    "\n",
    "# This DataFrame 'weekly_cases' now has weekly summed cases for each FIPS code.\n",
    "weekly_cases.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281a1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'weekly_cases' DataFrame has 'fips' and 'end_of_week' columns from earlier steps\n",
    "\n",
    "# Create a sorted list of unique FIPS codes\n",
    "unique_fips = weekly_cases['fips'].unique()\n",
    "\n",
    "# Create a sorted list of unique weeks (end_of_week dates)\n",
    "unique_weeks = weekly_cases['end_of_week'].unique()\n",
    "\n",
    "\n",
    "# Generate all combinations of FIPS codes and weeks\n",
    "import itertools\n",
    "\n",
    "fips_week_combinations = list(itertools.product(unique_fips, unique_weeks))\n",
    "\n",
    "# Convert to DataFrame\n",
    "fips_weeks = pd.DataFrame(fips_week_combinations, columns=['FIPS', 'Week'])\n",
    "fips_weeks = fips_weeks.merge(covid_data[[\"state\", \"fips\"]], left_on=\"FIPS\", right_on=\"fips\")\n",
    "covid_data= None\n",
    "fips_week_combinations= None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b87676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the `weekly_cases` data with `fips_weeks` to associate the number of new cases with each FIPS code and week.\n",
    "complete_data = pd.merge(fips_weeks, weekly_cases, how='left', left_on=['FIPS', 'Week'], right_on=['fips', 'end_of_week'])\n",
    "\n",
    "# Fill any NaN values that result from weeks where a FIPS code had no reported cases with zeros.\n",
    "complete_data['daily_new_cases'].fillna(0, inplace=True)\n",
    "\n",
    "# You now have a complete dataset to use as input for your Bayesian network.\n",
    "# Each row represents a node, with columns for the FIPS code, the week, and the number of new cases.\n",
    "\n",
    "complete_data.head(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb45f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Assuming this path is correct and points to your shapefile.\n",
    "shapefile_path = 'UScounties.shp'\n",
    "counties = gpd.read_file(shapefile_path)\n",
    "counties[\"FIPS\"] = counties[\"FIPS\"].astype(float)\n",
    "counties.info()\n",
    "counties.head(-20)\n",
    "weekly_cases= None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bec685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(fips_code):\n",
    "    # Ensure the FIPS code is a string if the DataFrame expects it as such\n",
    "    fips_float = float(fips_code)\n",
    "    \n",
    "    # Select the county based on FIPS code\n",
    "    county = counties[counties['FIPS'] == fips_float]\n",
    "\n",
    "    # If the county doesn't exist in the DataFrame, return an empty list\n",
    "    if county.empty:\n",
    "        \n",
    "        return []\n",
    "    \n",
    "    # Use spatial joins to find neighbors\n",
    "    neighbors = gpd.sjoin(counties, county, predicate='touches', how='inner')\n",
    "    # Get the FIPS codes of the neighbors. Depending on your GeoDataFrame, this could be 'FIPS_left' or just 'FIPS'\n",
    "    neighbor_fips = neighbors['FIPS_left'].tolist()\n",
    "\n",
    "    # Return a list of neighbors' FIPS codes, excluding the original county's FIPS code\n",
    "    return [f for f in neighbor_fips if f != fips_float]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3592c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_neighbors(27077.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "\n",
    "# Initialize an empty Bayesian Network\n",
    "bayesian_network = BayesianNetwork()\n",
    "\n",
    "# Add nodes. Assuming 'complete_data' is already loaded with the necessary columns.\n",
    "nodes = [(row['FIPS'], row['Week']) for index, row in complete_data.iterrows()]\n",
    "bayesian_network.add_nodes_from(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14596f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sorted list of unique weeks\n",
    "complete_data[complete_data[\"state\"] == \"Illinois\"]\n",
    "unique_weeks = sorted(complete_data['Week'].unique())\n",
    "\n",
    "for i in range(len(unique_weeks) - 1):\n",
    "    week = unique_weeks[i]\n",
    "    next_week = unique_weeks[i + 1]\n",
    "    current_week_fips = complete_data[complete_data['Week'] == week]['FIPS'].unique()\n",
    "    next_week_fips = complete_data[complete_data['Week'] == next_week]['FIPS'].unique()\n",
    "\n",
    "    for fips in current_week_fips:\n",
    "        neighbors = get_neighbors(fips)\n",
    "        for neighbor in neighbors:\n",
    "            # Check if each neighbor also has a record in the next week\n",
    "            if neighbor in next_week_fips:\n",
    "                # Append the tuple (current_week_fips, next_week_fips) to the potential edges\n",
    "                potential_edges.append(((fips, week), (neighbor, next_week)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49733056",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((potential_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7da6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "\n",
    "# Define the scoring function using BIC\n",
    "bic = BicScore(complete_data)\n",
    "\n",
    "# Initialize the Hill Climb Search without specifying the scoring method here\n",
    "hcs = HillClimbSearch(complete_data)\n",
    "\n",
    "# Run the Hill Climb Search using the potential edges as a whitelist and set the scoring method here\n",
    "best_model = hcs.estimate(white_list=potential_edges, scoring_method=bic)\n",
    "\n",
    "# Update the Bayesian Network with the edges from the best model found\n",
    "bayesian_network = BayesianNetwork(best_model.edges())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
